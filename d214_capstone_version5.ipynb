{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f51d64f-9f99-40aa-a02c-8c792c62dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import deque\n",
    "from surprise import Dataset, NormalPredictor, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from surprise import accuracy\n",
    "from surprise import accuracy, Dataset, Reader, SVD, KNNBaseline\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "import pprint\n",
    "import tempfile\n",
    "from typing import Dict, Text\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6762f32-1964-4ae4-9b62-70ed71389dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_titles = pd.read_csv('movie_titles.csv', header=None, encoding='ISO-8859-1', \n",
    "                          #names=['movie_id', 'year', 'title', 'description1', 'description2',\n",
    "                               # 'description3'])\n",
    "\n",
    "#movie_titles = movie_titles.drop(columns=['description1', 'description2', 'description3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a406ea4-ff4f-47a8-8baf-b02f3ed18113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alecclarkfeather/capstone_project\n"
     ]
    }
   ],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41500170-5b63-4b78-a415-d53c99fc6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/alecclarkfeather/capstone_project/'\n",
    "OLD_RMSE_PATH = PATH + 'rmse_train_test_folds/'\n",
    "OLD_HR_PATH = PATH + 'hit_rate_train_test_folds/'\n",
    "NEW_RMSE_PATH = PATH + 'rmse_folds_actual/'\n",
    "NEW_HR_PATH = PATH + 'hit_rate_folds_actual/'\n",
    "\n",
    "for i in range(5):\n",
    "    train_rmse_file = pd.read_csv(OLD_RMSE_PATH + f'train_df{i}.csv')\n",
    "    test_rmse_file = pd.read_csv(OLD_RMSE_PATH + f'test_df{i}.csv')\n",
    "    train_hr_file = pd.read_csv(OLD_HR_PATH + f'train_df_hit_rate{i}.csv')\n",
    "    test_hr_file = pd.read_csv(OLD_HR_PATH + f'test_df_hit_rate{i}.csv')\n",
    "    \n",
    "    train_rmse_file = train_rmse_file[['user_id', 'movie_id', 'rating']]\n",
    "    test_rmse_file = test_rmse_file[['user_id', 'movie_id', 'rating']]\n",
    "    \n",
    "    train_hr_file = train_hr_file[['user_id', 'movie_id', 'rating']]\n",
    "    test_hr_file = test_hr_file[['user_id', 'movie_id', 'rating']]\n",
    "    \n",
    "    train_rmse_file.to_csv(NEW_RMSE_PATH + f'actual_rmse_train{i}.csv', index=False, header=None)\n",
    "    test_rmse_file.to_csv(NEW_RMSE_PATH + f'actual_rmse_test{i}.csv', index=False, header=None)\n",
    "    \n",
    "    train_hr_file.to_csv(NEW_HR_PATH + f'train_hr{i}.csv', index=False, header=None)\n",
    "    test_hr_file.to_csv(NEW_HR_PATH + f'test_hr{i}.csv', index=False, header=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add672b0-6c86-4a01-8e75-d1c808788f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user_ratings_dict = pickle.load(open(PATH + 'top_user_ratings.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e52dee9-128b-4f6d-9fd4-73b94be38266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>841872</td>\n",
       "      <td>14454</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>689085</td>\n",
       "      <td>299</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2529854</td>\n",
       "      <td>11165</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2597445</td>\n",
       "      <td>10886</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2336656</td>\n",
       "      <td>3282</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0   841872     14454     5.0\n",
       "1   689085       299     5.0\n",
       "2  2529854     11165     5.0\n",
       "3  2597445     10886     4.0\n",
       "4  2336656      3282     5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ratings_df = pd.read_csv(PATH + 'top_ratings_df.csv')\n",
    "#top_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62cff15f-d6e8-45e6-80a0-49ae6dc6b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id    year                         title\n",
       "0         1  2003.0               Dinosaur Planet\n",
       "1         2  2004.0    Isle of Man TT 2004 Review\n",
       "2         3  1997.0                     Character\n",
       "3         4  1994.0  Paula Abdul's Get Up & Dance\n",
       "4         5  2004.0      The Rise and Fall of ECW"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26cb1eec-0ca4-4aba-b5bf-6a36873a08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=100):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f911b1cb-3c66-4930-967c-0995bab18938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1563732</td>\n",
       "      <td>7767</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548723</td>\n",
       "      <td>12471</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>698353</td>\n",
       "      <td>9628</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2229877</td>\n",
       "      <td>16377</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1058074</td>\n",
       "      <td>13094</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1618078</td>\n",
       "      <td>11781</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1777404</td>\n",
       "      <td>14253</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>577486</td>\n",
       "      <td>191</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>521846</td>\n",
       "      <td>2953</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>363825</td>\n",
       "      <td>16212</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1    2\n",
       "0  1563732   7767  2.0\n",
       "1   548723  12471  4.0\n",
       "2   698353   9628  4.0\n",
       "3  2229877  16377  4.0\n",
       "4  1058074  13094  5.0\n",
       "5  1618078  11781  5.0\n",
       "6  1777404  14253  4.0\n",
       "7   577486    191  4.0\n",
       "8   521846   2953  4.0\n",
       "9   363825  16212  3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rmse = pd.read_csv(NEW_RMSE_PATH + 'actual_rmse_train3.csv', header=None)\n",
    "#sample_rmse.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e6eb32-3c50-4e61-b34f-d9b653e087da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407114</td>\n",
       "      <td>7155</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2264272</td>\n",
       "      <td>13763</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443508</td>\n",
       "      <td>13853</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2649388</td>\n",
       "      <td>4157</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1014635</td>\n",
       "      <td>9170</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1927566</td>\n",
       "      <td>13359</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1781168</td>\n",
       "      <td>16879</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1813395</td>\n",
       "      <td>9756</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>797994</td>\n",
       "      <td>10734</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1098323</td>\n",
       "      <td>10080</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1    2\n",
       "0   407114   7155  4.0\n",
       "1  2264272  13763  3.0\n",
       "2   443508  13853  3.0\n",
       "3  2649388   4157  3.0\n",
       "4  1014635   9170  3.0\n",
       "5  1927566  13359  2.0\n",
       "6  1781168  16879  5.0\n",
       "7  1813395   9756  2.0\n",
       "8   797994  10734  4.0\n",
       "9  1098323  10080  4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_hr = pd.read_csv(NEW_HR_PATH + 'train_hr3.csv', header=None)\n",
    "#sample_hr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45522a08-cf92-45f7-9720-6a2e580cbf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on split 1a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4786\n",
      "RMSE: 1.0669\n",
      "RMSE: 1.0067\n",
      "Training on split 1b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4778\n",
      "RMSE: 1.0674\n",
      "RMSE: 1.0069\n",
      "Training on split 2a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4783\n",
      "RMSE: 1.0676\n",
      "RMSE: 1.0070\n",
      "Training on split 2b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4785\n",
      "RMSE: 1.0671\n",
      "RMSE: 1.0071\n",
      "Training on split 3a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4783\n",
      "RMSE: 1.0668\n",
      "RMSE: 1.0075\n",
      "Training on split 3b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4772\n",
      "RMSE: 1.0670\n",
      "RMSE: 1.0069\n",
      "Training on split 4a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4774\n",
      "RMSE: 1.0674\n",
      "RMSE: 1.0065\n",
      "Training on split 4b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4785\n",
      "RMSE: 1.0676\n",
      "RMSE: 1.0071\n",
      "Training on split 5a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4775\n",
      "RMSE: 1.0671\n",
      "RMSE: 1.0071\n",
      "Training on split 5b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.4781\n",
      "RMSE: 1.0673\n",
      "RMSE: 1.0069\n"
     ]
    }
   ],
   "source": [
    "rmse_baseline = []\n",
    "rmse_knn_cf = []\n",
    "rmse_svd = []\n",
    "\n",
    "for i in range(5):\n",
    "    reader1 = Reader(sep=',',rating_scale=(1,5))\n",
    "    train_file1 = NEW_RMSE_PATH + f'actual_rmse_train{i}.csv'\n",
    "    test_file1 = NEW_RMSE_PATH + f'actual_rmse_test{i}.csv'\n",
    "    folds_files1 = [(train_file1, test_file1)]\n",
    "    \n",
    "    data1 = Dataset.load_from_folds(folds_files1, reader=reader1)\n",
    "    \n",
    "    pkf1 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo1 = NormalPredictor()\n",
    "    cf_algo1 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo1 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf1.split(data1):\n",
    "        \n",
    "        print(f'Training on split {i+1}a')\n",
    "        \n",
    "        baseline_algo1.fit(trainset)\n",
    "        cf_algo1.fit(trainset)\n",
    "        svd_algo1.fit(trainset)\n",
    "        \n",
    "        preds_baseline1 = baseline_algo1.test(testset)\n",
    "        preds_cf1 = cf_algo1.test(testset)\n",
    "        preds_svd1 = svd_algo1.test(testset)\n",
    "        \n",
    "        score_baseline1 = accuracy.rmse(preds_baseline1)\n",
    "        score_cf1 = accuracy.rmse(preds_cf1)\n",
    "        score_svd1 = accuracy.rmse(preds_svd1)\n",
    "        \n",
    "        rmse_baseline.append(score_baseline1)\n",
    "        rmse_knn_cf.append(score_cf1)\n",
    "        rmse_svd.append(score_svd1)\n",
    "        \n",
    "        \n",
    "    reader2 = Reader(sep=',',rating_scale=(1,5))\n",
    "    test_file2 = NEW_RMSE_PATH + f'actual_rmse_train{i}.csv'\n",
    "    train_file2 = NEW_RMSE_PATH + f'actual_rmse_test{i}.csv'\n",
    "    folds_files2 = [(train_file2, test_file2)]\n",
    "    \n",
    "    data2 = Dataset.load_from_folds(folds_files2, reader=reader2)\n",
    "    \n",
    "    pkf2 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo2 = NormalPredictor()\n",
    "    cf_algo2 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo2 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf2.split(data2):\n",
    "        \n",
    "        print(f'Training on split {i+1}b')\n",
    "        \n",
    "        baseline_algo2.fit(trainset)\n",
    "        cf_algo2.fit(trainset)\n",
    "        svd_algo2.fit(trainset)\n",
    "        \n",
    "        preds_baseline2 = baseline_algo2.test(testset)\n",
    "        preds_cf2 = cf_algo2.test(testset)\n",
    "        preds_svd2 = svd_algo2.test(testset)\n",
    "        \n",
    "        score_baseline2 = accuracy.rmse(preds_baseline2)\n",
    "        score_cf2 = accuracy.rmse(preds_cf2)\n",
    "        score_svd2 = accuracy.rmse(preds_svd2)\n",
    "        \n",
    "        rmse_baseline.append(score_baseline2)\n",
    "        rmse_knn_cf.append(score_cf2)\n",
    "        rmse_svd.append(score_svd2)\n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6fbec2e-3ff2-482e-b867-6bcd12cba340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4786178666377692,\n",
       " 1.4777990851097553,\n",
       " 1.4783256722479254,\n",
       " 1.4785333953800346,\n",
       " 1.478334704011101,\n",
       " 1.4772170713102328,\n",
       " 1.4774247047343563,\n",
       " 1.4784686385124588,\n",
       " 1.477504314052595,\n",
       " 1.4780847719182082]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_baseline\n",
    "\n",
    "#rmse_baseline = []\n",
    "#rmse_knn_cf = []\n",
    "#rmse_svd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cfb83a5-91a7-4188-85b4-ce4ca10a6117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': [1.4786178666377692,\n",
       "  1.4777990851097553,\n",
       "  1.4783256722479254,\n",
       "  1.4785333953800346,\n",
       "  1.478334704011101,\n",
       "  1.4772170713102328,\n",
       "  1.4774247047343563,\n",
       "  1.4784686385124588,\n",
       "  1.477504314052595,\n",
       "  1.4780847719182082],\n",
       " 'cf': [1.0669471309284262,\n",
       "  1.0674027228800844,\n",
       "  1.0675938803678462,\n",
       "  1.067073054570045,\n",
       "  1.0667899415549194,\n",
       "  1.0669892014074274,\n",
       "  1.0674449762175207,\n",
       "  1.0675608352279466,\n",
       "  1.0670573055016608,\n",
       "  1.067256838080411],\n",
       " 'svd': [1.006683208406681,\n",
       "  1.006872323838753,\n",
       "  1.007039192583396,\n",
       "  1.0070924516192492,\n",
       "  1.007514474289824,\n",
       "  1.0068840097743916,\n",
       "  1.0064842103785587,\n",
       "  1.007107457789272,\n",
       "  1.0070685886655626,\n",
       "  1.0069185298387704]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_results = dict(baseline=rmse_baseline, cf=rmse_knn_cf, svd=rmse_svd)\n",
    "rmse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef70cfb6-0589-4d89-bbe3-8fbe92bbe24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>cf</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.478618</td>\n",
       "      <td>1.066947</td>\n",
       "      <td>1.006683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.477799</td>\n",
       "      <td>1.067403</td>\n",
       "      <td>1.006872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.478326</td>\n",
       "      <td>1.067594</td>\n",
       "      <td>1.007039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.478533</td>\n",
       "      <td>1.067073</td>\n",
       "      <td>1.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.478335</td>\n",
       "      <td>1.066790</td>\n",
       "      <td>1.007514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.477217</td>\n",
       "      <td>1.066989</td>\n",
       "      <td>1.006884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.477425</td>\n",
       "      <td>1.067445</td>\n",
       "      <td>1.006484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.478469</td>\n",
       "      <td>1.067561</td>\n",
       "      <td>1.007107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.477504</td>\n",
       "      <td>1.067057</td>\n",
       "      <td>1.007069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.478085</td>\n",
       "      <td>1.067257</td>\n",
       "      <td>1.006919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline        cf       svd\n",
       "0  1.478618  1.066947  1.006683\n",
       "1  1.477799  1.067403  1.006872\n",
       "2  1.478326  1.067594  1.007039\n",
       "3  1.478533  1.067073  1.007092\n",
       "4  1.478335  1.066790  1.007514\n",
       "5  1.477217  1.066989  1.006884\n",
       "6  1.477425  1.067445  1.006484\n",
       "7  1.478469  1.067561  1.007107\n",
       "8  1.477504  1.067057  1.007069\n",
       "9  1.478085  1.067257  1.006919"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_results_df = pd.DataFrame(rmse_results)\n",
    "rmse_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e3ba9d-155c-4377-851b-5825b116e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_results_df.to_csv(PATH + 'rmse_results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c900cbe-62a1-4ddc-86ff-0c97814f0f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on split 1a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 1b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 2a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 2b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "hr_baseline = []\n",
    "hr_knn_cf = []\n",
    "hr_svd = []\n",
    "\n",
    "for i in range(5):\n",
    "    reader1 = Reader(sep=',',rating_scale=(1,5))\n",
    "    train_file1 = NEW_HR_PATH + f'train_hr{i}.csv'\n",
    "    test_file1 = NEW_HR_PATH + f'test_hr{i}.csv'\n",
    "    folds_files1 = [(train_file1, test_file1)]\n",
    "    \n",
    "    data1 = Dataset.load_from_folds(folds_files1, reader=reader1)\n",
    "    \n",
    "    pkf1 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo1 = NormalPredictor()\n",
    "    cf_algo1 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo1 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf1.split(data1):\n",
    "        \n",
    "        print(f'Training on split {i+1}a')\n",
    "        \n",
    "        baseline_algo1.fit(trainset)\n",
    "        cf_algo1.fit(trainset)\n",
    "        svd_algo1.fit(trainset)\n",
    "        \n",
    "        preds_baseline1 = baseline_algo1.test(testset)\n",
    "        preds_cf1 = cf_algo1.test(testset)\n",
    "        preds_svd1 = svd_algo1.test(testset)\n",
    "        \n",
    "        top_n_baseline1 = get_top_n(preds_baseline1)\n",
    "        top_n_cf1 = get_top_n(preds_cf1)\n",
    "        top_n_svd1 = get_top_n(preds_svd1)\n",
    "        \n",
    "        total_users_baseline1 = 0\n",
    "        recs_with_top_movie_baseline1 = 0\n",
    "        total_users_cf1 = 0\n",
    "        recs_with_top_movie_cf1 = 0\n",
    "        total_users_svd1 = 0\n",
    "        recs_with_top_movie_svd1 = 0\n",
    "        \n",
    "        for user_id in top_n_baseline1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_baseline1 += 1\n",
    "            num_recs = len(top_n_baseline1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_baseline1[user_id]][top_number]\n",
    "            pred_top_movie = baseline_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_baseline1 += 1\n",
    "                \n",
    "        for user_id in top_n_cf1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_cf1 += 1\n",
    "            num_recs = len(top_n_cf1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_cf1[user_id]][top_number]\n",
    "            pred_top_movie = cf_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_cf1 += 1\n",
    "                \n",
    "        for user_id in top_n_svd1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_svd1 += 1\n",
    "            num_recs = len(top_n_svd1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_svd1[user_id]][top_number]\n",
    "            pred_top_movie = svd_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_svd1 += 1\n",
    "            \n",
    "        hr_baseline.append(recs_with_top_movie_baseline1 / total_users_baseline1)\n",
    "        hr_knn_cf.append(recs_with_top_movie_cf1 / total_users_cf1)\n",
    "        hr_svd.append(recs_with_top_movie_svd1 / total_users_svd1)\n",
    "        \n",
    "        \n",
    "    reader2 = Reader(sep=',',rating_scale=(1,5))\n",
    "    test_file2 = NEW_HR_PATH + f'train_hr{i}.csv'\n",
    "    train_file2 = NEW_HR_PATH + f'test_hr{i}.csv'\n",
    "    folds_files2 = [(train_file2, test_file2)]\n",
    "    \n",
    "    data2 = Dataset.load_from_folds(folds_files2, reader=reader2)\n",
    "    \n",
    "    pkf2 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo2 = NormalPredictor()\n",
    "    cf_algo2 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo2 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf2.split(data2):\n",
    "        \n",
    "        print(f'Training on split {i+1}b')\n",
    "        \n",
    "        baseline_algo2.fit(trainset)\n",
    "        cf_algo2.fit(trainset)\n",
    "        svd_algo2.fit(trainset)\n",
    "        \n",
    "        preds_baseline2 = baseline_algo2.test(testset)\n",
    "        preds_cf2 = cf_algo2.test(testset)\n",
    "        preds_svd2 = svd_algo2.test(testset)\n",
    "        \n",
    "        top_n_baseline2 = get_top_n(preds_baseline2)\n",
    "        top_n_cf2 = get_top_n(preds_cf2)\n",
    "        top_n_svd2 = get_top_n(preds_svd2)\n",
    "        \n",
    "        total_users_baseline2 = 0\n",
    "        recs_with_top_movie_baseline2 = 0\n",
    "        total_users_cf2 = 0\n",
    "        recs_with_top_movie_cf2 = 0\n",
    "        total_users_svd2 = 0\n",
    "        recs_with_top_movie_svd2 = 0\n",
    "        \n",
    "        for user_id in top_n_baseline2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_baseline2 += 1\n",
    "            num_recs = len(top_n_baseline2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_baseline2[user_id]][top_number]\n",
    "            pred_top_movie = baseline_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_baseline2 += 1\n",
    "                \n",
    "        for user_id in top_n_cf2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_cf2 += 1\n",
    "            num_recs = len(top_n_cf2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_cf2[user_id]][top_number]\n",
    "            pred_top_movie = cf_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_cf2 += 1\n",
    "                \n",
    "        for user_id in top_n_svd2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_svd2 += 1\n",
    "            num_recs = len(top_n_svd2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_svd2[user_id]][top_number]\n",
    "            pred_top_movie = svd_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_svd2 += 1\n",
    "                \n",
    "        hr_baseline.append(recs_with_top_movie_baseline2 / total_users_baseline2)\n",
    "        hr_knn_cf.append(recs_with_top_movie_cf2 / total_users_cf2)\n",
    "        hr_svd.append(recs_with_top_movie_svd2 / total_users_svd2)\n",
    "                \n",
    "        \n",
    "              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e80787b7-a5a6-40f0-9698-f641bc16fe90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4584132406598979,\n",
       " 0.4607263191596408,\n",
       " 0.4593281007582024,\n",
       " 0.46033313381395896]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hr_baseline \n",
    "#hr_knn_cf \n",
    "#hr_svd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03f2c860-cb5c-4bbd-8256-2d4b1ec816b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on split 3a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 3b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 4a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 4b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,4):\n",
    "    reader1 = Reader(sep=',',rating_scale=(1,5))\n",
    "    train_file1 = NEW_HR_PATH + f'train_hr{i}.csv'\n",
    "    test_file1 = NEW_HR_PATH + f'test_hr{i}.csv'\n",
    "    folds_files1 = [(train_file1, test_file1)]\n",
    "    \n",
    "    data1 = Dataset.load_from_folds(folds_files1, reader=reader1)\n",
    "    \n",
    "    pkf1 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo1 = NormalPredictor()\n",
    "    cf_algo1 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo1 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf1.split(data1):\n",
    "        \n",
    "        print(f'Training on split {i+1}a')\n",
    "        \n",
    "        baseline_algo1.fit(trainset)\n",
    "        cf_algo1.fit(trainset)\n",
    "        svd_algo1.fit(trainset)\n",
    "        \n",
    "        preds_baseline1 = baseline_algo1.test(testset)\n",
    "        preds_cf1 = cf_algo1.test(testset)\n",
    "        preds_svd1 = svd_algo1.test(testset)\n",
    "        \n",
    "        top_n_baseline1 = get_top_n(preds_baseline1)\n",
    "        top_n_cf1 = get_top_n(preds_cf1)\n",
    "        top_n_svd1 = get_top_n(preds_svd1)\n",
    "        \n",
    "        total_users_baseline1 = 0\n",
    "        recs_with_top_movie_baseline1 = 0\n",
    "        total_users_cf1 = 0\n",
    "        recs_with_top_movie_cf1 = 0\n",
    "        total_users_svd1 = 0\n",
    "        recs_with_top_movie_svd1 = 0\n",
    "        \n",
    "        for user_id in top_n_baseline1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_baseline1 += 1\n",
    "            num_recs = len(top_n_baseline1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_baseline1[user_id]][top_number]\n",
    "            pred_top_movie = baseline_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_baseline1 += 1\n",
    "                \n",
    "        for user_id in top_n_cf1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_cf1 += 1\n",
    "            num_recs = len(top_n_cf1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_cf1[user_id]][top_number]\n",
    "            pred_top_movie = cf_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_cf1 += 1\n",
    "                \n",
    "        for user_id in top_n_svd1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_svd1 += 1\n",
    "            num_recs = len(top_n_svd1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_svd1[user_id]][top_number]\n",
    "            pred_top_movie = svd_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_svd1 += 1\n",
    "            \n",
    "        hr_baseline.append(recs_with_top_movie_baseline1 / total_users_baseline1)\n",
    "        hr_knn_cf.append(recs_with_top_movie_cf1 / total_users_cf1)\n",
    "        hr_svd.append(recs_with_top_movie_svd1 / total_users_svd1)\n",
    "        \n",
    "        \n",
    "    reader2 = Reader(sep=',',rating_scale=(1,5))\n",
    "    test_file2 = NEW_HR_PATH + f'train_hr{i}.csv'\n",
    "    train_file2 = NEW_HR_PATH + f'test_hr{i}.csv'\n",
    "    folds_files2 = [(train_file2, test_file2)]\n",
    "    \n",
    "    data2 = Dataset.load_from_folds(folds_files2, reader=reader2)\n",
    "    \n",
    "    pkf2 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo2 = NormalPredictor()\n",
    "    cf_algo2 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo2 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf2.split(data2):\n",
    "        \n",
    "        print(f'Training on split {i+1}b')\n",
    "        \n",
    "        baseline_algo2.fit(trainset)\n",
    "        cf_algo2.fit(trainset)\n",
    "        svd_algo2.fit(trainset)\n",
    "        \n",
    "        preds_baseline2 = baseline_algo2.test(testset)\n",
    "        preds_cf2 = cf_algo2.test(testset)\n",
    "        preds_svd2 = svd_algo2.test(testset)\n",
    "        \n",
    "        top_n_baseline2 = get_top_n(preds_baseline2)\n",
    "        top_n_cf2 = get_top_n(preds_cf2)\n",
    "        top_n_svd2 = get_top_n(preds_svd2)\n",
    "        \n",
    "        total_users_baseline2 = 0\n",
    "        recs_with_top_movie_baseline2 = 0\n",
    "        total_users_cf2 = 0\n",
    "        recs_with_top_movie_cf2 = 0\n",
    "        total_users_svd2 = 0\n",
    "        recs_with_top_movie_svd2 = 0\n",
    "        \n",
    "        for user_id in top_n_baseline2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_baseline2 += 1\n",
    "            num_recs = len(top_n_baseline2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_baseline2[user_id]][top_number]\n",
    "            pred_top_movie = baseline_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_baseline2 += 1\n",
    "                \n",
    "        for user_id in top_n_cf2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_cf2 += 1\n",
    "            num_recs = len(top_n_cf2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_cf2[user_id]][top_number]\n",
    "            pred_top_movie = cf_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_cf2 += 1\n",
    "                \n",
    "        for user_id in top_n_svd2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_svd2 += 1\n",
    "            num_recs = len(top_n_svd2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_svd2[user_id]][top_number]\n",
    "            pred_top_movie = svd_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_svd2 += 1\n",
    "                \n",
    "        hr_baseline.append(recs_with_top_movie_baseline2 / total_users_baseline2)\n",
    "        hr_knn_cf.append(recs_with_top_movie_cf2 / total_users_cf2)\n",
    "        hr_svd.append(recs_with_top_movie_svd2 / total_users_svd2)\n",
    "                \n",
    "        \n",
    "              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a833bfc-6d99-4a39-bf3b-fb512e4062f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4584132406598979,\n",
       " 0.4607263191596408,\n",
       " 0.4593281007582024,\n",
       " 0.46033313381395896,\n",
       " 0.4606618628235922,\n",
       " 0.45971889188354637,\n",
       " 0.46130416882681224,\n",
       " 0.4604322853342379]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hr_baseline \n",
    "#hr_knn_cf \n",
    "#hr_svd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f82b354-3cfa-4645-80c8-61e48b2f4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on split 5a\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training on split 5b\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,5):\n",
    "    reader1 = Reader(sep=',',rating_scale=(1,5))\n",
    "    train_file1 = NEW_HR_PATH + f'train_hr{i}.csv'\n",
    "    test_file1 = NEW_HR_PATH + f'test_hr{i}.csv'\n",
    "    folds_files1 = [(train_file1, test_file1)]\n",
    "    \n",
    "    data1 = Dataset.load_from_folds(folds_files1, reader=reader1)\n",
    "    \n",
    "    pkf1 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo1 = NormalPredictor()\n",
    "    cf_algo1 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo1 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf1.split(data1):\n",
    "        \n",
    "        print(f'Training on split {i+1}a')\n",
    "        \n",
    "        baseline_algo1.fit(trainset)\n",
    "        cf_algo1.fit(trainset)\n",
    "        svd_algo1.fit(trainset)\n",
    "        \n",
    "        preds_baseline1 = baseline_algo1.test(testset)\n",
    "        preds_cf1 = cf_algo1.test(testset)\n",
    "        preds_svd1 = svd_algo1.test(testset)\n",
    "        \n",
    "        top_n_baseline1 = get_top_n(preds_baseline1)\n",
    "        top_n_cf1 = get_top_n(preds_cf1)\n",
    "        top_n_svd1 = get_top_n(preds_svd1)\n",
    "        \n",
    "        total_users_baseline1 = 0\n",
    "        recs_with_top_movie_baseline1 = 0\n",
    "        total_users_cf1 = 0\n",
    "        recs_with_top_movie_cf1 = 0\n",
    "        total_users_svd1 = 0\n",
    "        recs_with_top_movie_svd1 = 0\n",
    "        \n",
    "        for user_id in top_n_baseline1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_baseline1 += 1\n",
    "            num_recs = len(top_n_baseline1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_baseline1[user_id]][top_number]\n",
    "            pred_top_movie = baseline_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_baseline1 += 1\n",
    "                \n",
    "        for user_id in top_n_cf1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_cf1 += 1\n",
    "            num_recs = len(top_n_cf1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_cf1[user_id]][top_number]\n",
    "            pred_top_movie = cf_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_cf1 += 1\n",
    "                \n",
    "        for user_id in top_n_svd1.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_svd1 += 1\n",
    "            num_recs = len(top_n_svd1[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_svd1[user_id]][top_number]\n",
    "            pred_top_movie = svd_algo1.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_svd1 += 1\n",
    "            \n",
    "        hr_baseline.append(recs_with_top_movie_baseline1 / total_users_baseline1)\n",
    "        hr_knn_cf.append(recs_with_top_movie_cf1 / total_users_cf1)\n",
    "        hr_svd.append(recs_with_top_movie_svd1 / total_users_svd1)\n",
    "        \n",
    "        \n",
    "    reader2 = Reader(sep=',',rating_scale=(1,5))\n",
    "    test_file2 = NEW_HR_PATH + f'train_hr{i}.csv'\n",
    "    train_file2 = NEW_HR_PATH + f'test_hr{i}.csv'\n",
    "    folds_files2 = [(train_file2, test_file2)]\n",
    "    \n",
    "    data2 = Dataset.load_from_folds(folds_files2, reader=reader2)\n",
    "    \n",
    "    pkf2 = PredefinedKFold()\n",
    "    \n",
    "    baseline_algo2 = NormalPredictor()\n",
    "    cf_algo2 = KNNBaseline(sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "    svd_algo2 = SVD()\n",
    "    \n",
    "    for trainset, testset in pkf2.split(data2):\n",
    "        \n",
    "        print(f'Training on split {i+1}b')\n",
    "        \n",
    "        baseline_algo2.fit(trainset)\n",
    "        cf_algo2.fit(trainset)\n",
    "        svd_algo2.fit(trainset)\n",
    "        \n",
    "        preds_baseline2 = baseline_algo2.test(testset)\n",
    "        preds_cf2 = cf_algo2.test(testset)\n",
    "        preds_svd2 = svd_algo2.test(testset)\n",
    "        \n",
    "        top_n_baseline2 = get_top_n(preds_baseline2)\n",
    "        top_n_cf2 = get_top_n(preds_cf2)\n",
    "        top_n_svd2 = get_top_n(preds_svd2)\n",
    "        \n",
    "        total_users_baseline2 = 0\n",
    "        recs_with_top_movie_baseline2 = 0\n",
    "        total_users_cf2 = 0\n",
    "        recs_with_top_movie_cf2 = 0\n",
    "        total_users_svd2 = 0\n",
    "        recs_with_top_movie_svd2 = 0\n",
    "        \n",
    "        for user_id in top_n_baseline2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_baseline2 += 1\n",
    "            num_recs = len(top_n_baseline2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_baseline2[user_id]][top_number]\n",
    "            pred_top_movie = baseline_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_baseline2 += 1\n",
    "                \n",
    "        for user_id in top_n_cf2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_cf2 += 1\n",
    "            num_recs = len(top_n_cf2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_cf2[user_id]][top_number]\n",
    "            pred_top_movie = cf_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_cf2 += 1\n",
    "                \n",
    "        for user_id in top_n_svd2.keys():\n",
    "            top_movie_id = top_user_ratings_dict[int(user_id)]\n",
    "            total_users_svd2 += 1\n",
    "            num_recs = len(top_n_svd2[user_id])\n",
    "            top_number = int(num_recs * 0.25)\n",
    "            boundary_for_user = [rec[1] for rec in top_n_svd2[user_id]][top_number]\n",
    "            pred_top_movie = svd_algo2.predict(user_id, \n",
    "                                                   str(top_movie_id),\n",
    "                                                   top_ratings_df[(top_ratings_df['user_id']==int(user_id))&\n",
    "                                                                 (top_ratings_df['movie_id']==top_movie_id)]['rating'])\n",
    "            if float(pred_top_movie[3]) > boundary_for_user:\n",
    "                recs_with_top_movie_svd2 += 1\n",
    "                \n",
    "        hr_baseline.append(recs_with_top_movie_baseline2 / total_users_baseline2)\n",
    "        hr_knn_cf.append(recs_with_top_movie_cf2 / total_users_cf2)\n",
    "        hr_svd.append(recs_with_top_movie_svd2 / total_users_svd2)\n",
    "                \n",
    "        \n",
    "              \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6d98ac7-2ff0-458e-9306-3381c1f300f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4584132406598979,\n",
       " 0.4607263191596408,\n",
       " 0.4593281007582024,\n",
       " 0.46033313381395896,\n",
       " 0.4606618628235922,\n",
       " 0.45971889188354637,\n",
       " 0.46130416882681224,\n",
       " 0.4604322853342379,\n",
       " 0.4595550811109628,\n",
       " 0.45912129458126577]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hr_baseline \n",
    "#hr_knn_cf \n",
    "#hr_svd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f5277d-c217-43b3-b649-08a2d73d0cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline': [0.29656134785708566,\n",
       "  0.29703389184491774,\n",
       "  0.2977154815862403,\n",
       "  0.2989969385848866,\n",
       "  0.29587098250028593,\n",
       "  0.2980455094751047,\n",
       "  0.2973681802933732,\n",
       "  0.2980299039916455,\n",
       "  0.29686421777006805,\n",
       "  0.2984229341504501],\n",
       " 'cf': [0.43922785693315997,\n",
       "  0.4390007775456999,\n",
       "  0.43889971067087,\n",
       "  0.43797679729466976,\n",
       "  0.43965458080750314,\n",
       "  0.4388740426732337,\n",
       "  0.4395603976700924,\n",
       "  0.4392753827566099,\n",
       "  0.43853294954154676,\n",
       "  0.43962330307257247],\n",
       " 'svd': [0.4584132406598979,\n",
       "  0.4607263191596408,\n",
       "  0.4593281007582024,\n",
       "  0.46033313381395896,\n",
       "  0.4606618628235922,\n",
       "  0.45971889188354637,\n",
       "  0.46130416882681224,\n",
       "  0.4604322853342379,\n",
       "  0.4595550811109628,\n",
       "  0.45912129458126577]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_results = dict(baseline=hr_baseline, cf=hr_knn_cf, svd=hr_svd)\n",
    "hr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7639357a-5ed5-4d1e-ba38-1ebad48106f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline</th>\n",
       "      <th>cf</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.296561</td>\n",
       "      <td>0.439228</td>\n",
       "      <td>0.458413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.297034</td>\n",
       "      <td>0.439001</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297715</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.459328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298997</td>\n",
       "      <td>0.437977</td>\n",
       "      <td>0.460333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295871</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>0.460662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.298046</td>\n",
       "      <td>0.438874</td>\n",
       "      <td>0.459719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.297368</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.461304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.298030</td>\n",
       "      <td>0.439275</td>\n",
       "      <td>0.460432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.296864</td>\n",
       "      <td>0.438533</td>\n",
       "      <td>0.459555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.298423</td>\n",
       "      <td>0.439623</td>\n",
       "      <td>0.459121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   baseline        cf       svd\n",
       "0  0.296561  0.439228  0.458413\n",
       "1  0.297034  0.439001  0.460726\n",
       "2  0.297715  0.438900  0.459328\n",
       "3  0.298997  0.437977  0.460333\n",
       "4  0.295871  0.439655  0.460662\n",
       "5  0.298046  0.438874  0.459719\n",
       "6  0.297368  0.439560  0.461304\n",
       "7  0.298030  0.439275  0.460432\n",
       "8  0.296864  0.438533  0.459555\n",
       "9  0.298423  0.439623  0.459121"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_results_df = pd.DataFrame(hr_results)\n",
    "hr_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b67995e-0d6c-46e4-afda-4ff78bc0a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_results_df.to_csv(PATH + 'hr_results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a78d4-e7c7-48f9-938f-ea080e0c07d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
